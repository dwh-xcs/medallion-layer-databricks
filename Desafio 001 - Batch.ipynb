{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38d5b2f1-562e-42f9-8090-8897bae0cf9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A ideia √© criar um pipeline **realista**, mas did√°tico ‚Äî com **camadas Bronze ‚Üí Silver ‚Üí Gold (Fato e Dimens√£o)** ‚Äî usando **Databricks + Spark**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "381bdf36-bfba-4661-95d4-5909a1975e43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üíæ 1Ô∏è‚É£ Cen√°rio proposto\n",
    "\n",
    "Vamos simular uma pipeline de **vendas de e-commerce** ‚Äî um cl√°ssico e √≥timo exemplo para aprendizado.\n",
    "\n",
    "**Fonte (arquivo de entrada):**\n",
    "\n",
    "* Um arquivo CSV de **pedidos de compra** contendo transa√ß√µes brutas exportadas do sistema de vendas.\n",
    "\n",
    "### üßæ Exemplo de arquivo (`orders_raw.csv`)\n",
    "\n",
    "| order_id | order_date | customer_id | product_id | quantity | unit_price | country   | payment_method | status    |\n",
    "| -------- | ---------- | ----------- | ---------- | -------- | ---------- | --------- | -------------- | --------- |\n",
    "| 1001     | 2024-05-10 | C001        | P001       | 2        | 150.00     | Brazil    | Credit Card    | Delivered |\n",
    "| 1002     | 2024-05-11 | C002        | P002       | 1        | 80.00      | Argentina | PIX            | Cancelled |\n",
    "| 1003     | 2024-05-11 | C001        | P003       | 3        | 50.00      | Brazil    | Credit Card    | Delivered |\n",
    "| 1004     | 2024-05-12 | C003        | P001       | 1        | 150.00     | Chile     | Debit Card     | Delivered |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db46f730-4798-4804-8ee5-c000ba41c233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚öôÔ∏è 2Ô∏è‚É£ Objetivos da Pipeline\n",
    "\n",
    "| Camada     | Objetivo                 | Descri√ß√£o                                                                       |\n",
    "| ---------- | ------------------------ | ------------------------------------------------------------------------------- |\n",
    "| **Bronze** | Ingest√£o                 | Ingerir o arquivo *raw*, armazenar sem transforma√ß√£o (data lake).               |\n",
    "| **Silver** | Limpeza e enriquecimento | Tratar nulos, tipos, normalizar pa√≠ses, calcular `total_price`.                 |\n",
    "| **Gold**   | Modelagem dimensional    | Criar tabelas **Dimens√£o** (Cliente, Produto, Tempo, Pa√≠s) e **Fato** (Vendas). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2eafc40f-8810-443f-9475-65c325cc1cc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß± 3Ô∏è‚É£ Estrutura de pastas no Data Lake\n",
    "\n",
    "```\n",
    "/mnt/datalake/\n",
    "    ‚îú‚îÄ‚îÄ bronze/\n",
    "    ‚îÇ     ‚îî‚îÄ‚îÄ orders/\n",
    "    ‚îú‚îÄ‚îÄ silver/\n",
    "    ‚îÇ     ‚îî‚îÄ‚îÄ orders_clean/\n",
    "    ‚îî‚îÄ‚îÄ gold/\n",
    "          ‚îú‚îÄ‚îÄ dim_customer/\n",
    "          ‚îú‚îÄ‚îÄ dim_product/\n",
    "          ‚îú‚îÄ‚îÄ dim_date/\n",
    "          ‚îú‚îÄ‚îÄ dim_country/\n",
    "          ‚îî‚îÄ‚îÄ fact_sales/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f426e0e2-773d-4657-858d-e486fd45f3c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üí° 4Ô∏è‚É£ Transforma√ß√µes esperadas\n",
    "\n",
    "### üî∏ Bronze\n",
    "\n",
    "* Leitura direta do CSV.\n",
    "* Armazenar em formato **Delta** (`bronze.orders`).\n",
    "\n",
    "```python\n",
    "df_bronze = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .csv(\"/mnt/raw/orders_raw.csv\")\n",
    ")\n",
    "df_bronze.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/bronze/orders\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a27dab9a-e7f6-4ef5-bf01-aed9348967d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üî∏ Silver\n",
    "\n",
    "Limpezas e enriquecimentos:\n",
    "\n",
    "* Converter tipos (`quantity` ‚Üí int, `unit_price` ‚Üí float).\n",
    "* Normalizar `country` e `status`.\n",
    "* Criar campo `total_price = quantity * unit_price`.\n",
    "* Filtrar apenas `status = 'Delivered'`.\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import col, upper, trim, when\n",
    "\n",
    "df_silver = (\n",
    "    df_bronze\n",
    "    .withColumn(\"quantity\", col(\"quantity\").cast(\"int\"))\n",
    "    .withColumn(\"unit_price\", col(\"unit_price\").cast(\"double\"))\n",
    "    .withColumn(\"total_price\", col(\"quantity\") * col(\"unit_price\"))\n",
    "    .withColumn(\"country\", trim(upper(col(\"country\"))))\n",
    "    .filter(col(\"status\") == \"Delivered\")\n",
    ")\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/silver/orders_clean\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb15031f-cfa9-42ed-87b3-3f0ed9317203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß© 5Ô∏è‚É£ Modelagem Dimensional (Camada Gold)\n",
    "\n",
    "### üéØ Fato e Dimens√µes\n",
    "\n",
    "| Tabela          | Chave        | Descri√ß√£o               |\n",
    "| --------------- | ------------ | ----------------------- |\n",
    "| **Fato_Vendas** | `sk_venda`   | M√©tricas das transa√ß√µes |\n",
    "| **Dim_Cliente** | `sk_cliente` | Clientes √∫nicos         |\n",
    "| **Dim_Produto** | `sk_produto` | Produtos √∫nicos         |\n",
    "| **Dim_Tempo**   | `sk_data`    | Datas de venda          |\n",
    "| **Dim_Pais**    | `sk_pais`    | Pa√≠ses padronizados     |\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Dimens√µes\n",
    "\n",
    "#### üßç Dim_Cliente\n",
    "\n",
    "| Campo       | Tipo   |\n",
    "| ----------- | ------ |\n",
    "| sk_cliente  | INT    |\n",
    "| customer_id | STRING |\n",
    "\n",
    "#### üì¶ Dim_Produto\n",
    "\n",
    "| Campo      | Tipo   |\n",
    "| ---------- | ------ |\n",
    "| sk_produto | INT    |\n",
    "| product_id | STRING |\n",
    "| unit_price | DOUBLE |\n",
    "\n",
    "#### üìÖ Dim_Tempo\n",
    "\n",
    "| Campo      | Tipo |\n",
    "| ---------- | ---- |\n",
    "| sk_data    | INT  |\n",
    "| order_date | DATE |\n",
    "| ano        | INT  |\n",
    "| mes        | INT  |\n",
    "| dia        | INT  |\n",
    "\n",
    "#### üåé Dim_Pais\n",
    "\n",
    "| Campo   | Tipo   |\n",
    "| ------- | ------ |\n",
    "| sk_pais | INT    |\n",
    "| country | STRING |\n",
    "\n",
    "---\n",
    "\n",
    "### üí∞ Fato_Vendas\n",
    "\n",
    "| Campo       | Tipo   | Descri√ß√£o   |\n",
    "| ----------- | ------ | ----------- |\n",
    "| sk_venda    | INT    | PK          |\n",
    "| sk_cliente  | INT    | FK cliente  |\n",
    "| sk_produto  | INT    | FK produto  |\n",
    "| sk_data     | INT    | FK data     |\n",
    "| sk_pais     | INT    | FK pa√≠s     |\n",
    "| quantity    | INT    | Quantidade  |\n",
    "| total_price | DOUBLE | Valor total |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "806d892a-d4b3-4789-b20b-a5541a07994a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ü™Ñ 6Ô∏è‚É£ C√≥digo exemplo - Cria√ß√£o das dimens√µes e fato\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import monotonically_increasing_id, year, month, dayofmonth\n",
    "\n",
    "# Carregar camada Silver\n",
    "df_silver = spark.read.format(\"delta\").load(\"/mnt/datalake/silver/orders_clean\")\n",
    "\n",
    "# Dimens√µes\n",
    "dim_cliente = df_silver.select(\"customer_id\").distinct().withColumn(\"sk_cliente\", monotonically_increasing_id())\n",
    "dim_produto = df_silver.select(\"product_id\", \"unit_price\").distinct().withColumn(\"sk_produto\", monotonically_increasing_id())\n",
    "dim_pais = df_silver.select(\"country\").distinct().withColumn(\"sk_pais\", monotonically_increasing_id())\n",
    "dim_data = (\n",
    "    df_silver.select(\"order_date\")\n",
    "    .distinct()\n",
    "    .withColumn(\"ano\", year(\"order_date\"))\n",
    "    .withColumn(\"mes\", month(\"order_date\"))\n",
    "    .withColumn(\"dia\", dayofmonth(\"order_date\"))\n",
    "    .withColumn(\"sk_data\", monotonically_increasing_id())\n",
    ")\n",
    "\n",
    "# Fato\n",
    "df_fact = (\n",
    "    df_silver\n",
    "    .join(dim_cliente, \"customer_id\", \"left\")\n",
    "    .join(dim_produto, [\"product_id\", \"unit_price\"], \"left\")\n",
    "    .join(dim_pais, \"country\", \"left\")\n",
    "    .join(dim_data, \"order_date\", \"left\")\n",
    "    .select(\n",
    "        \"sk_cliente\", \"sk_produto\", \"sk_pais\", \"sk_data\",\n",
    "        \"quantity\", \"total_price\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Escrita Gold\n",
    "dim_cliente.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/gold/dim_customer\")\n",
    "dim_produto.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/gold/dim_product\")\n",
    "dim_pais.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/gold/dim_country\")\n",
    "dim_data.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/gold/dim_date\")\n",
    "df_fact.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/datalake/gold/fact_sales\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26d67591-5f46-4fd2-84e3-0db22d35ef37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ 7Ô∏è‚É£ Poss√≠veis Requisitos Extras\n",
    "\n",
    "Voc√™ pode adicionar para deixar o projeto mais completo:\n",
    "\n",
    "| Tipo                   | Requisito                                                    |\n",
    "| ---------------------- | ------------------------------------------------------------ |\n",
    "| **Qualidade de dados** | Implementar checagem de nulos e logs de rejei√ß√£o             |\n",
    "| **Particionamento**    | `partitionBy(\"ano\",\"mes\")` em tabelas gold                   |\n",
    "| **Agendamento**        | Executar via **Job do Databricks** diariamente               |\n",
    "| **Monitoramento**      | Criar uma tabela de controle de ingest√£o (`metadata_ingest`) |\n",
    "| **Alertas**            | Enviar erro no Slack/Teams quando a ingest√£o falhar          |\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Desafio 001 - Batch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
